# -*- coding: utf-8 -*-
"""WIND TURBINE  ENERGY PREDICTION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_cQV2Zi1YNntowQQc_iGHzHGh7MRXSiX

# ***PROJECT OBJECTIVE***

In this notebook, we are going to be creating several machine learning models for the predictions of energy generated by a wind turbine system, given the weather conditions an hour prior.

**Target Column:** System Power Generated

**Metrics:** Mean squared errror and Mean Absolute error

# ***WORKFLOW***
In order to accomplish the above goal, we need to perform the following
1. Data loading and understanding
2. Cleaning the data
3. Feature engineering
4. Exploratory Data Analysis
5. Modelling
6. Hyperparameter Tuning
7. Model Selection

---

**1. DATA CLEANING**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import datetime as dt

data = pd.read_csv('/content/TexasTurbine.csv')

data.head()

data.shape

data.columns

"""**2. DATA CLEANING**"""

data.head()

data.isna().sum()

#Converting Time stamp column to datetime data type and inputting the new format we want the Time stamp column in.
data['Time stamp'] = pd.to_datetime(data['Time stamp'], format = "%b %d, %I:%M %p").dt.strftime('%Y-%m-%d %H:%M:%S')

#Replacing the year 1900 generated during the Time stamp column conversion
data['Time stamp'] = data['Time stamp'].str.replace("1900", "2021")

#Convert back to datetime pandas format
data['Time stamp'] = pd.to_datetime(data['Time stamp'])

data.index = data['Time stamp']
data.drop('Time stamp', axis = 1, inplace = True)

data.head()

data.duplicated().sum()

"""**3. FEATURE ENGINEERING**"""

#Extract the following information from date index: day of the week, week, month, quarter

def extract_features(dataframe):
  dataframe = dataframe.copy()
  dataframe['Quarter'] = dataframe.index.quarter
  dataframe['Month'] = dataframe.index.month
  dataframe['Week'] = dataframe.index.isocalendar().week.astype(int)
  dataframe['Hour'] = dataframe.index.hour
  return dataframe

def map_month_to_season(Month):
  if 3 <= Month <= 5:
    return "Spring"
  elif 6 <= Month <= 8:
    return "Summer"
  elif 9 <= Month <= 11:
    return "Fall"
  else:
    return "Winter"

data = extract_features(data)

data['Season'] = data['Month'].apply(map_month_to_season)

data.dtypes

data.columns

data.columns = ['power_generated', 'Wind_speed',
       'Wind_direction', 'Pressure', 'Temperature',
       'Quarter', 'Month', 'Week', 'Hour', 'Season']

"""**4. EXPLORATORY DATA ANALYSIS(UNIVARIATE)**

Univariate: Power generated, Wind speed,
       Wind direction, Pressure, Temperature and Season
"""

#Visualizing the distribution for Power generated
plt.figure(figsize = (12,4)) #Speicify the plot size
sns.histplot(data['power_generated'], bins = 40) #Create histogram

data.power_generated.describe()

"""Trying to discover any indicating factor why we have this kind of ditribution, with the highest count being 0 power generated."""

#Selecting rows with zero power generated
data[data['power_generated'] <= 0]

""" In 822 instances, Power generated was zero


"""

data[data['power_generated'] <= 0]['Season'].value_counts()

#Barplot
season_plot = data[data['power_generated'] <= 0]['Season'].value_counts()

plt.figure(figsize = (8,6))
sns.barplot(x = season_plot.index, y = season_plot, palette = 'viridis')

plt.title('Zero Power Generation by season')
plt.xlabel('Season')
plt.ylabel('Count')

#Boxplot: We get to visualize outliers, if there are
sns.boxplot(data['power_generated'])

"""There is an absence of outliers in the power generated column"""

#Checking the distribution of wind speed
plt.figure(figsize = (12,4))
sns.histplot(data['Wind_speed'], bins = 40)

"""The wind speed is normally distributed"""

sns.boxplot(data['Wind_direction'])

"""We have the presence of outliers which are continuous and consecutive after the maximum occuring value. We can conclude that the severity is not too large.

If required the outliers could be removes by capping or transforming.

"""

plt.figure(figsize = (12, 4))
sns.histplot(data['Wind_direction'], bins = 40)

"""The distribution is almost binomial. We have our peak (the larger center of tendency) at almost 140, but observe that there are smaller peaks in our distribution. In conclusion it is not a strictly normal distribution."""

#Showing the distribution of Pressure values
plt.figure(figsize = (12, 4))
sns.histplot(data['Pressure'], bins = 40)

"""We have a normal distribution

Why are we checking out normal distribution,

-first thing is to observe whether there are skews and also check for the presence of outliers. There is a need to correct some of this cases most of the time, especially with outliers.

-Secondly to check if the data makes sense, it would not make sense if pressure was not normallly distributed, same as speed. There are some things that happen in real life taht follow certain distribution, for example age in a particular community, income. so if we are not getting normal distribution, questions would need to be asked, like why is it so
"""

#Showing the distribution of Temperature values
plt.figure(figsize = (12, 4))
sns.histplot(data['Temperature'], bins = 40)

"""In this case, we have a data distribution skews to the right, this could be due to the fact that there is an existence of much warmth to hot seasons present in our dataset. That is we have the fall, summer and spring more. Winter is the only season that experiences true cold."""

#Barplot
Temp_plot = data['Temperature']
sea_plot = data['Season']

plt.figure(figsize = (8,6))
sns.barplot(x = sea_plot, y = Temp_plot, palette = 'viridis')

plt.title('Temperature distribution by season')
plt.xlabel('Season')
plt.ylabel('Temp')

"""**4. EXPLORATORY DATA ANALYSIS(MULTIVARIATE)**"""

#Temperature vs Pressure
plt.figure(figsize = (10, 5))
sns.scatterplot(data = data, x = 'Temperature', y = 'Pressure', hue = 'Season')

"""Winter: Generally the days are colder having most of its temperature below 20 degrees cel.

Spring: High temperature at low pressure(non cloudy days) & low temperature at high pressure

Summer: This season generally has hotter days with most of its temperature above 20 degrees cel.

Fall: This season has a wide range of temperature and pressure.
"""

#Create bins for Power Generated values
num_bins = 4
binned_data = pd.cut(data['power_generated'], bins = num_bins)

#Creating fig
plt.figure(figsize = (10,5))
sns.scatterplot(data = data, x = 'Temperature', y = 'Pressure', hue = binned_data, palette='viridis')
plt.title('Scattered plot of temperature vs pressure with power generated-color mapped')
plt.xlabel('Temperature')
plt.ylabel('Pressure')
plt.legend(title = 'Power generate category', loc = 'upper right')
plt.show()

"""nothing to infer other than large occurence of blue dots (0-751.002)"""

#Observe the effect of season on power generation
sns.boxplot(data = data, y = 'power_generated', x = 'Season', palette='viridis')

"""Fall: Has the lowest average value of power generated, making fall season the least productive season.

Spring: Has the highest average value of power generated, making spring season the most productive season.
"""

data.head()

#Wind speed and Power generation
sns.boxplot(data = data, y = 'Wind_speed', x = 'Season', palette='viridis')

#month and Power generation
sns.boxplot(data = data, y = 'power_generated', x = 'Month', palette='viridis')

"""A cyclical pattern can be observed when power generated is compared with Months"""

#month and Wind speed
sns.boxplot(data = data, y = 'Wind_speed', x = 'Month', palette='viridis')

"""Same cyclical pattern can be seen here too plotting wind speed vs months."""

#Scattered plot for wind speed vs power generated
plt.figure(figsize = (10, 5))
sns.scatterplot(data = data, x = 'Wind_speed', y = 'power_generated')
plt.title('Scatter plot for wind speed vs power generated')

data

"""**POWER GENERATION CURVE**

Power generation is null at a wind speed less than 2.5

**BINNING USING PANDAS .cut function**

Going further better visualize the relationship between Power generated and Wind direction, we will be binning the continuous data of the Wind direction into intervals.
"""

data['Wind_direction']
bin_labels = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']
bin_edge = [-1, 45, 90, 135, 180, 225, 270, 315, 360]
binned_data = pd.cut(data['Wind_direction'], bins= bin_edge, labels = bin_labels)

sns.boxplot(y= data['power_generated'], x= binned_data, palette='viridis')
plt.title('Box plot for wind speed vs power generated')

"""Wind direction influences the Power generated value"""

#Adding the wind orientation componenet to our dataset
data['Wind_Orientatation'] = binned_data

data.head()

#modified_data = '/content/TexasTurbine.csv'
#data.to_csv(modified_data, index=False)

#from google.colab import files

# Download the file
#files.download(modified_data)

"""**5. ENCODING AND MODELING**

For this dataset we would be using Mean encoding also known as Target encoding.
Target Encoding replaces the categorical value with the mean of the target variable. This technique is useful for high cardinality features.

***While using the target encoder, we need to be mindful of Data leakage***

When using target encoding, we replace each category with the mean (or another statistic) of the target variable for that category. If this encoding is performed on the entire dataset, the model might gain access to the target variable information that it would not have during actual predictions. This can lead to data leakage, as the encoded feature would contain information derived from the target variable of the entire dataset, including the test set.
"""

#getting the last 30% of our data for testing
len(data)*0.3

train_data = data[:-2628]
test_data = data[-2628:]

train_data

#Encoding for Season column
Season_mean = train_data.groupby('Season')['power_generated'].mean()
data['Season_mean_encoded'] = data['Season'].map(Season_mean)

#Encoding for Season column
Wind_Orientatation_mean = train_data.groupby('Wind_Orientatation')['power_generated'].mean()
data['Wind_Orientatation_mean_encoded'] = data['Wind_Orientatation'].map(Wind_Orientatation_mean)

data['Season_mean_encoded'].to_csv('season_encoding.csv',index = False)
data['Wind_Orientatation_mean_encoded'].to_csv('wind_encoding.csv',index = False)

data

data.drop(['Season', 'Wind_Orientatation'], axis = 1, inplace = True)

data.head()

"""***Modeling***"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error

data.columns

#splitting the dataset into target and features
target = 'power_generated'
features =['Wind_speed', 'Wind_direction', 'Pressure', 'Temperature', 'Quarter', 'Month', 'Week', 'Hour', 'Season_mean_encoded', 'Wind_Orientatation_mean_encoded']

train_data = data[:-2628]
test_data = data[-2628:]

#Setting the xy train and xy test
X_train = train_data[features]
y_train = train_data[target]

X_test = test_data[features]
y_test = test_data[target]

# Initialize the models
rf_model = RandomForestRegressor()
svm_model = SVR()
lr_model = LinearRegression()
rgb_model = GradientBoostingRegressor()


# Train and evaluate each model
models = {
      "Random Forest": rf_model,
      "Support Vector Machine": svm_model,
      "Linear Regressor": lr_model,
      "Gradient Boosting Regressor": rgb_model
    }

# Initializing an empty list to save the evaluation result along with the corresponding model.
results_list = []

for name, model in models.items():
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  mse = mean_squared_error(y_test, y_pred)
  mae = mean_absolute_error(y_test, y_pred)

  results_list.append({'Model': name, 'Mean squared error': mse, 'Mean absolute error': mae})

result = pd.DataFrame(results_list)

result

# y_test.mean()

"""# **6. HYPERPARAMETER**

Hyperparameter tuning is a crucial step in the machine learning process where you optimize the parameters that govern the training process of your model to improve its performance.

**Hyperopt** is a Python library that uses Bayesian optimization to perform hyperparameter tuning.

**Bayesian** optimization is a strategy for finding the optimal hyperparameters of a model by building a probabilistic model of the objective function and using it to select the most promising hyperparameters to evaluate.
"""

len(X_train)*0.2

#LAST 1200 VALUES
X_val  = X_train[-1200:]
y_val = y_train[-1200:]

#EVERYTHING ESLSE FOR TRAINING
X_train = X_train[:-1200]
y_train = y_train[:-1200]

import numpy as np
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials

#Create a space
space = {
    'n_estimators': hp.quniform('n_estimators', 100, 300, 1),
    'max_depth':hp.quniform('max_depth', 5, 20, 1),
    'max_features':hp.choice('max_features', ['sqrt', 'log2', None])
}

#objective ==> sample from this space, create a random forest model. evaluate the model, loss/mse
def objective(params):
  n_estimators = int(params['n_estimators'])
  max_depth = int(params['max_depth'])
  max_features = params['max_features']

  rf_model = RandomForestRegressor(
      n_estimators = n_estimators,
      max_depth = max_depth,
      max_features = max_features,
      random_state = 42
  )
  rf_model.fit(X_train, y_train)
  predictions = rf_model.predict(X_val)

  mse = mean_squared_error(y_val, predictions)
  return{'loss': mse, 'status': STATUS_OK}

#minimize the objective:fmin
trials = Trials()

best = fmin(
  fn = objective,
  space = space,
  algo = tpe.suggest,
  max_evals = 100,
  trials = trials,
  verbose = 1
)

print('Best Hyperparameters:', best)

best_RandomForest_Hyperparameter = {'max_depth': 15.0, 'max_features': 2, 'n_estimators': 236.0}

import numpy as np
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials

#Create a space
space = {
    'n_estimators': hp.quniform('n_estimators', 100, 300, 1),
    'max_depth':hp.quniform('max_depth', 5, 20, 1),
    'learning_rate':hp.loguniform('learning_rate', -5,0),
    'subsample': hp.uniform('subsample', 0.1, 1.0)
}

#objective ==> sample from this space, create a random forest model. evaluate the model, loss/mse
def objective(params):
  n_estimators = int(params['n_estimators'])
  max_depth = int(params['max_depth'])


  gb_model = GradientBoostingRegressor(
      n_estimators = n_estimators,
      max_depth = max_depth,
      learning_rate = params['learning_rate'],
      subsample = params['subsample'],
      random_state = 42
  )
  gb_model.fit(X_train, y_train)
  predictions = gb_model.predict(X_val)

  mse = mean_squared_error(y_val, predictions)
  return{'loss': mse, 'status': STATUS_OK}

#minimize the objective:fmin
trials = Trials()

best = fmin(
  fn = objective,
  space = space,
  algo = tpe.suggest,
  max_evals = 100,
  trials = trials,
  verbose = 1
)

print('Best Hyperparameters:', best)

Best_GradientBoosting_Hyperparameter = {'learning_rate': 0.028193916434926043, 'max_depth': 15.0, 'n_estimators': 284.0, 'subsample': 0.14157727141089976}

"""# **MODEL SELECTION**"""

train_data = data[:-2628]
test_data = data[-2628:]

#splitting the dataset into target and features
target = 'power_generated'
features =['Wind_speed', 'Wind_direction', 'Pressure', 'Temperature', 'Quarter', 'Month', 'Week', 'Hour', 'Season_mean_encoded', 'Wind_Orientatation_mean_encoded']

#Setting the xy train and xy test
X_train = train_data[features]
y_train = train_data[target]

X_test = test_data[features]
y_test = test_data[target]

best_RandomForest_Hyperparameter

rf_model = RandomForestRegressor(
    n_estimators = 236,
    max_depth = 15,
    max_features = 2,
    random_state = 42
)


rf_model.fit(X_train, y_train)
rf_predictions = rf_model.predict(X_test)

rf_mse = mean_squared_error(y_test, rf_predictions)
rf_mae = mean_absolute_error(y_test, rf_predictions)

print('MSE:', rf_mse, 'MAE:', rf_mae )

"""***THERE IS A CASE OF OVERFITTING HERE***"""

Best_GradientBoosting_Hyperparameter

gb_model = GradientBoostingRegressor(
    n_estimators = 284,
    max_depth = 15,
    learning_rate = 0.028193916434926043,
    subsample = 0.14157727141089976,
    random_state = 42
)

gb_model.fit(X_train, y_train)
gb_predictions = gb_model.predict(X_test)

gb_mse = mean_squared_error(y_test, gb_predictions)
gb_mae = mean_absolute_error(y_test, gb_predictions)

print('MSE:', gb_mse, 'MAE:', gb_mae )

"""***BEST PERFORMING MODEL: GRADIENT BOOSTING UNDER THE BEST HYPERPARAMETER***"""